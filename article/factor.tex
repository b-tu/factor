\documentclass[12pt]{article}

% change to a4 layout
\usepackage{geometry}
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=15mm,
}

% maths packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}

% references
\usepackage{natbib}

% table packages
\usepackage{booktabs} 

% colour
\usepackage{xcolor}

% enumerate
\usepackage[shortlabels]{enumitem}

% images
\usepackage{graphicx}
\graphicspath{ {figures/} }

% theorems
% \newtheorem{definition}{Definition}[section]
% \newtheorem{lemma}{Lemma}[section]
% \newtheorem{proposition}{Proposition}[section]
% \newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}{Remark}[section]
% \newtheorem{example}{Example}[section]
% \newtheorem{corollary}{Corollary}[section]
% \newtheorem{assumption}{Assumption}[section]

% full stop after paragraph
\makeatletter
\renewcommand\paragraph{%
	\@startsection{paragraph}
	{4}
	{\z@}
	{3.25ex \@plus1ex \@minus.2ex}
	{-1em}
	{\normalfont\normalsize\bfseries\maybe@addperiod}%
}
\newcommand{\maybe@addperiod}[1]{%
	#1\@addpunct{.}%
}
\makeatother

% hyperlinks
\usepackage[pagebackref]{hyperref}       
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=blue,
	citecolor=blue,      
	urlcolor=blue,
}
\renewcommand*{\backref}[1]{}
\renewcommand*{\backrefalt}[4]{%
	\ifcase #1 Not cited.%
	\or        Cited on page~#2.%
	\else      Cited on pages~#2.%
	\fi}

% reference   
\usepackage{cleveref}
\crefname{section}{Section}{Sections}
% \crefname{figure}{Figure}{Figures}
% \crefname{definition}{Definition}{Definitions}
% \crefname{lemma}{Lemma}{Lemmas}
% \crefname{proposition}{Proposition}{Propositions}
% \crefname{theorem}{Theorem}{Theorems}
\crefname{remark}{Remark}{Remarks}
% \crefname{corollary}{Corollary}{Corollaries}
% \crefname{appendix}{Appendix}{Appendices}
% \crefname{assumption}{Assumption}{Assumptions}
% \crefname{example}{Example}{Examples}
% \crefname{table}{Table}{Tables}

% references
\renewcommand\bibname{References}
\usepackage[nottoc,numbib]{tocbibind}

% paragraphs
\usepackage[parfill]{parskip}

% caption
\usepackage[font=footnotesize,labelfont=bf, textfont=it]{caption}

% correct bookmarks
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
	\let\Cref\crtCref
	\let\cref\crtcref
}

% definitions of some handy macros
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Active portfolio management}
\author{
	b-tu
}

\begin{document}
\maketitle
The goal of this article is to present a focussed and subjective summary on some of the key ideas covered in the book by \cite{grinold1999} and the surrounding literature on asset portfolio management.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Notation}
For additional generality, we adopt our own notation in this work, which differs slightly from the notation adopted by \cite{grinold1999}. For bookkeeping purposes, we now highlight some of the key notation that will be used throughout this work.

\paragraph{Space of financial investments.} We let $\mathbb{I}$ denote the space (or universe) of investments. An individual investment will be denoted by $\mathcal{I} \in \mathbb{I}$. Each investment will be assumed to be a comprised of a weighted collection of positions on $N-1$ unique assets $\mathbb{A} = \{\mathcal{A}_1, \dots, \mathcal{A}_{N-1}\} \subset \mathbb{I}$ and cash holding $\mathcal{A}_N := \mathcal{C}$. More formally, every investment $\mathcal{I}$ can be identified by a weight vector 
\begin{equation}
	\mathbb{W} := \{\mathbf{w} = (w^{(1)},\dots, w^{(N)}) \in \mathbb{R}^{N+1}: \mathbf{w}^T \mathbf{1}_{N} = 1\},
\end{equation}
where $\mathbf{1}_N \in \mathbb{R}^{N}$ is a vector of ones. Notably, the weight components $w^{(n)} \in \mathbb{R}$ can either be positive (for a long position) or negative (for a short position). When $w^{(N)} = 0$, the portfolio is said to be fully-invested; when $w^{(N)} = 1$ the portfolio is said to be cash-neutral; when $w^{(1)},...,w^{(N-1)} \geq 0$ the portfolio is said to be long-only.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background concepts}
The goal of this section is to highlight some of the core conventions and ideas that are often present in the finance literature.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Returns}
The return of an investment is often reported in the percentage range. More precisely, one does not report the raw numerical return (i.e.\ the change in profit), but instead one reports the rate of return (i.e.\ the relative change in profit). Concretely, suppose we have an investment $\mathcal{I} \in \mathbb{I}$ whose value is given by $v_{t_0}(\mathcal{I}) \in \mathbb{R}$ at time $t_0$ and $v_T(\mathcal{I}) \in \mathbb{R}$ at some future time $t$, then the return of this investment (or portfolio) at this latest time is given by
\begin{equation}
    R_t^{\text{p}} := R_t(\mathcal{I}) := \frac{v_t(\mathcal{I}) - v_{t_0}(\mathcal{I})}{v_{t_0}(\mathcal{I})} \in \mathbb{R}.
    \label{eqn:return}
\end{equation}
Notice that this number tends to infinity when the initial value approaches zero. That is, in the limit we are getting infinite return from a prior investment of nothing.

\begin{remark}
	[Other value streams] In practice, one must also account for other profits gained by holding onto the investment in equation \eqref{eqn:return}. For example, one might also include gains from dividends. Out of convenience, we ignore subtle technicalities such as this.
\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Everything is relative}
Performance assessment is traditionally defined on a relative basis. That is, one typically computes the performance of an investment in comparison to another one. Specifically, we are often interested in the return of an investment $\mathcal{I} \in \mathbb{I}$ relative to some benchmark $\mathcal{B} \in \mathbb{I}$:
\begin{equation}
    R_t^{\text{p}} - R_t^{\text{b}} := R_t(\mathcal{I}) - R_t(\mathcal{B}).
    \label{eqn:relative_return}
\end{equation}
Practitioners often set this benchmark rate to either the risk-free rate or the market rate. Notably, when the risk-free rate is used, this relative return is referred to as the excess return. Otherwise, this relative return is commonly referred to as the active return.

\paragraph{Risk-free rate} The risk-free rate, $R_t^{\text{rf}} := R_t(\mathcal{B}^{\text{rf}})$, refers to the (hypothetical) minimum rate of return that one might desire from an investment. Typically, this rate is set to the return of a financial product whose risk is minimal\footnote{Ideally, one would like to consider a zero risk investment---although realistically there is always a risk associated with any investment.}. In practice, it is common to see this rate being set to the return of some Treasury bill (T-bill) or a long-term government bond yield. Notably, we will assume that the return of cash follows the risk-free rate.

\paragraph{Market rate} The market rate, $R_t^{\text{m}} := R_t(\mathcal{B}^{\text{m}})$, usually refers to the return achieved by a financial product that tries to match the market as a whole (or at least some subset of it). This market portfolio is usually constructed by taking all of the assets in the desired market and then weighting them accordingly to their market capitalisation.

\begin{remark}
	[Empty investment] Note that we recover the original notion of return \eqref{eqn:return} if we set our benchmark to the empty investment.
\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The meaning of risk}
Following \cite{grinold1999}, the risk associated with an investment is defined as the standard deviation of its return. More precisely, the risk associated with an investment $\mathcal{I} \in \mathbb{I}$, at a time $t > 0$, is
\begin{equation}
	\text{Risk}[\mathcal{I}] := \text{Std}[R_t^{\text{p}}] = \sqrt{\mathbb{V}\text{ar}[R_t^{\text{p}}]},
\end{equation}
and similarly, the risk of the active return \eqref{eqn:relative_return} is 
\begin{equation}
	\text{Risk}[(\mathcal{I}, \mathcal{B})] := \text{Std}[R_t^{\text{p}} - R_t^{\text{b}}] = \sqrt{\mathbb{V}\text{ar}[R_t^{\text{p}} - R_t^{\text{b}}]}.
\end{equation}
This latter risk is sometimes referred to as the active risk or the tracking error.

\paragraph{Other measures of risk} As discussed by \citet[Chapter 3]{grinold1999}, there are many possible alternatives to the standard deviation as a notion of risk. Although empirically, they suggest that there is little to gain from exploring these alternatives---at least from a performance-to-cost standpoint.

\paragraph{Idiosyncratic and systematic risk} The risk associated entirely from an individual asset $\mathcal{A} \in \mathbb{I}$ is referred to as the idiosyncratic risk of $\mathcal{A}$. These risk can typically be mitigated (or even eliminated) by constructing a more diversified portfolio. The other sources of risk are collectively referred to as the systematic risk. Conceptually, these are the risk involved with holding any investment. Moreover, by construction, systematic risk cannot be diversified away (i.e.\ they represent the non-diversifiable risk).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The nature of time}
The distinction between an ex-ante (before the event) approach and an ex-post (after the event) approach is often very subtle in the finance literature. For example, one might take an ex-ante approach when one is interested in forecasting and making predictions of the future. In contrast, one might take an ex-post approach in the performance assessment setting, where one is interested in assessing the quality\footnote{Here the term quality is defined in the philosophical sense. In general, it is very hard to actually quantify what distinguishes a skillful investor and a lucky one.} of a strategy or a portfolio manager.

\paragraph{Risk analysis} A core problem in asset management is concerned with the quantification of risk. It is important to note that one is interested in estimating risk in both the ex-ante and ex-post setting. In the ex-ante setting, we are interested estimating risk in order to incorporate it into our active decision-making. Whilst, in the ex-post setting, we are interested in assessing risk in order to identify its main drivers and also to properly assess the realised performance of an investment or portfolio manager.

\paragraph{Information set} We denote the historical information set, at time $t > 0$, by $\mathcal{D}_t \in \mathbb{D}$, where $\mathbb{D}$ denotes the set of all possible historical information sets. Confusingly, some authors abuse this notation because they allow it to be defined ambiguously in order to accommodate for both the ex-ante and ex-post setting. More specifically, in the ex-ante (or ex-post) setting, these authors let $\mathcal{D}_t$ denote the information set containing all of the information available at the beginning (or end) of time $t$, respectively. This convention is convenient from a writing perspective as it covers both of these temporal settings simultaneously. On the other hand, it is definitely confusing from a reader perspective who could easily be misled. To avoid this confusion, in this work, we will just look at the ex-ante set-up where the historical data $\mathcal{D}_t$ is used to represent all the information that is known at the beginning on time $t$. The ex-post setting can be handled similarly.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Garbage in, garbage out}
A central tenet that is echoed throughout the book by \cite{grinold1999} is the idea that the ability to identify and exploit ``superior information'' is what separates a good active manager from a bad one. In other words, to generate excess returns, one needs to be diligent in both their ability to collect useful information and also their ability to use it effectively. Most of the work presented by \cite{grinold1999} focusses on addressing the latter problem. We will cover a selection of these ideas in the following sections. The former problem, however, is a practical challenge that is much more an art than a science. Regardless of how one approaches this information retrieval problem, one inevitably will fall upon the well-know adage: ``garbage in, garbage out''. That is, our inability to identify information of a `reasonable' quality will, more often than not, lead to low quality output (i.e.\ garbage). Therefore, it remains an important and unquestionable part of asset management, that one must aspire to collect high quality data in order to facilitate better decision making.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The efficient market hypothesis}
The Efficient-Market Hypothesis (EMH) proposed by \cite{fama1970jf} states that the price of an asset or investment reflects all of the available information. That is, there should not be consistent opportunities for an investor to outperform the market. In particular, \cite{fama1970jf} proposed a number of different variants of the EMH. These variants mainly differ on what the notion of ``available information" means. Namely, whether this is just any data available about past prices (weak), any publicly available information (semi-strong) or any possible information that exist in the world (strong). Overall, the debate on whether the EMH (or some variant of it) holds in practice is a contentious one---see \cite{malkiel2003jep} for more details. Regardless of its validity, there are still many people out there who participate in the financial markets with an interest in beating it!
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mean-variance trade-off}
\label{sec:mean_variance}
The goal of Modern Portfolio Theory (MPT) \citep{markowitz1952jf} is to find portfolios which achieves the greatest expected return for a given user-specified risk level. More formally, suppose we have a risk level of $\delta \geq 0$, then the goal of interest is to solve the following mean-variance optimisation problem:
\begin{align}
	\max_{\mathbf{w} \in \mathbb{H}} \mathbf{w}^T \boldsymbol{\mu}_t
	\quad
	\text{subject to}
	\quad 
	\mathbf{w}^T\boldsymbol{\Sigma}_t \mathbf{w} \leq \delta^2,
	\label{eqn:mean_variance_problem}
\end{align}
for any time $t > 0$, where the $\boldsymbol{\mu}_t \in \mathbb{R}^N$ and $\boldsymbol{\Sigma}_t \in \mathbb{R}^{N \times N}$ denotes the mean and covariance matrix of the returns of the base assets (and cash). That is, the reward vector is denoted by
\begin{equation}
	\mathbf{R}_t = (R_t(\mathcal{A}_1), \dots, R_t(\mathcal{A}_N)) \in \mathbb{R}^N,
\end{equation}
whilst the mean vector and covariance matrix is given by $\boldsymbol{\mu}_t := \mathbb{E}[\mathbf{R}_t] \in \mathbb{R}^N$ and $\boldsymbol{\Sigma}_t := \mathbb{V}\text{ar}[\mathbf{R}_t] \in \mathbb{R}^{N \times N}$, respectively. The cash holding is often assumed to be known and fixed to the risk-free rate. In particular, $\mathbb{E}[\mu_t^{(N)}] = \mathcal{R}_t^{\text{rf}}$ and $\Sigma_t^{(i, j)} = 0$ when either $i$ or $j$ is equal to $N$.

\paragraph{Estimating the asset return statistics} One of the key challenges involved with deploying an MPT solution comes from the fact that the mean vector and covariance matrix of interest is unknown in practice and therefore has to be estimated (or predicted) from the available data $\mathcal{D}_t \in \mathbb{D}$. The mean vector has $\mathcal{O}(N)$ elements that has to be estimated, whilst the covariance matrix has $\mathcal{O}(N^2)$ number of elements to be estimated. In practice, one does not usually have enough data points at each time $t$ in order to efficiently estimate the covariance matrix with high precision. As a result, practitioners typically try to reduce the dimensionality of this estimation problem by making some reasonable modelling assumptions on the excess returns of the assets. For instance a popular modelling framework are factor models (\cref{sec:factor_models}), which effectively reduces the dimensionality of the covariance matrix to $\mathcal{O}(K^2 + N)$, where $K$ is the number of factors specified by the user---see \cref{sec:factor_models} for more details.
%%%%%% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modelling the returns}
One of the main problems in active portfolio management is concerned with the modelling of excess returns \eqref{eqn:relative_return}. In particular, one often tries to model the excess returns of the assets, at time $t > 0$, as a function of the information set:
\begin{equation}
    \mathbf{R}_t - R^{\text{rf}}_t \mathbf{1}_N = g_t(\mathcal{D}_t) + \boldsymbol{\epsilon}_t,
    \label{eqn:return_model}
\end{equation}
where $\mathcal{D}_t \in \mathbb{D}$ denotes the $t$-th information set, $g_t: \mathbb{D} \rightarrow \mathbb{R}^N$ denotes a (potentially random\footnote{The modelling function $g_t$ might depend on parameters that are treated as random variables. For instance, this might take place when we adopt a Bayesian modelling framework.}) modelling function and $\boldsymbol{\epsilon}_t \in \mathbb{R}$ denotes the random residual. In the following paragraphs, we list some notable ideas that underpin this general model for excess returns \eqref{eqn:return_model}.

\paragraph{Dependence on the investor} Notably, the form of the information set $\mathcal{D}_t$ and modelling function $g_t$ is something that is specified by the user; the residual $\boldsymbol{\epsilon}_t$ denotes everything else that is left over. On practical level, this means that different investors can obtain different results even if they adopt the same modelling function. 

\paragraph{Information uncertainty} In the most general case, the information set can be treated as a random variable. The randomness of this quantity stems from the intrinsic uncertainty that naturally arises from the collection, retrieval and processing of real-world data. Conventionally though, it is common to see this information set (or at least some part of it) being treated as a deterministic realisation of an estimation or computation procedure. This is usually done out of numerical convenience. \textcolor{magenta}{Question to self: Is there anything to gain from a more fully probabilistic treatment?}

\paragraph{Residual uncertainty} The residual $\boldsymbol{\epsilon}_t = \mathbf{R}_t - R^{\text{rf}}_t \mathbf{1}_N - g_t(\mathcal{D}_t)$ models the remaining discrepancy that is not accounted for by the ``explained'' part of the excess returns $g_t(\mathcal{D}_t)$. Note here that the residual $\boldsymbol{\epsilon}_t$ is a random variable because the excess returns is modelled as a random variable.

\paragraph{Space of models} The modelling function $g_t$ is assumed to live in some reasonably flexible space. Much of the earlier work in the space considered the space of linear functions \citep{sharpe1964jf, ross1976joet}. More recently, there has been a growing interest in using machine learning methods in order to learn more expressive non-linear models \citep{gu2020trofs}.

\paragraph{Imposing structure on the risk} As highlighted in \cref{sec:mean_variance}, one of the goals involved with modelling the excess returns is to estimate the covariance matrix of the excess returns. For this purpose, it is common to try to embed some structure into the model which helps facilitate this dimensionality reduction. In particular, a common strategy is to enforce that the ``explained'' part of the model $g_t(\mathcal{D}_t)$ is used to account for the systematic returns (and risk), whilst the remaining part $\boldsymbol{\epsilon}_t$ accounts for the idiosyncratic return (and risk). Such a structure is imposed in factor models. \textcolor{magenta}{Question to self: Is this strategy always the best way to proceed, can we not estimate the covariance through another decomposition?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Factor models}
\label{sec:factor_models}
Early work on modelling returns centred on the setting where the modelling function was linear. In particular, these linear models, otherwise known as factor models, try to relate the excess returns of an asset with the returns of different factors. These factors are user-specified and therefore this linear modelling framework offers a lot of flexibility. Despite this, it is common for practitioners to use well-known factors that have been proposed before in the literature. We will now present a targetted overview on this topic. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Multi-factor model} The multi-factor model assumes that the excess returns obeys the following linear model
\begin{align}
	\mathbf{R}_t - R^{\text{rf}} \mathbf{1}_N 
	&= \mathbf{B}_t \mathbf{f}_t + \mathbf{u}_t
	\label{eqn:multi_factor_model}
\end{align}
at time $t>0$. The variables in the model are outlined as follows:
\begin{itemize}
	\item $\mathbf{f}_t = (f_t^{(1)}, \dots, f_t^{(K)})^T \in \mathbb{R}^K$ is the factor returns vector. This vector is generally treated as a random variable.
	\item $\mathbf{B}_t \in \mathbb{R}^{N \times K}$ is the exposure matrix, whose elements $B_t^{(n, k)} \in\ \mathbb{R}$ are the factor loadings which represent the exposure (or sensitivity) of asset $n \in [N]$ to factor $k \in [K]$. This is commonly treated as a deterministic variable.
	\item $\mathbf{u}_t = (u_t^{(1)}, \dots, u_t^{(N)})^T \in \mathbb{R}^N$ are the asset residuals or the idiosyncratic returns. Namely, these are the excess returns of an asset that cannot be explained by the (systematic) factors.
\end{itemize}

\paragraph{Statistics} The expectation and variance of the excess returns of any investment $\mathcal{I} \in \mathbb{I}$ under \eqref{eqn:multi_factor_model} is then given by:
\begin{align}
	\mathbb{E}[R_t^{\text{p}}] &= \mathbf{w}^T (\mathbb{E}[\mathbf{B}_t \mathbf{f}_t] + \mathbb{E}[\mathbf{u}_t]),
	\\
	\mathbb{V}\text{ar}[R_t^{\text{p}}] 
	&= \mathbf{w}^T \mathbb{V}\text{ar}[\mathbf{B}_t \mathbf{f}_t + \mathbf{u}_t] \mathbf{w}
	\\
	&= \mathbf{w}^T \left(\mathbb{V}\text{ar}[\mathbf{B}_t \mathbf{f}_t] + 2\text{Cov}[\mathbf{B}_t \mathbf{f}_t, \mathbf{u}_t] + \mathbb{V}\text{ar}[\mathbf{u}_t]\right) \mathbf{w}.
\end{align}

\paragraph{Alphas and betas} The alphas of the assets are defined as the expectation of the idiosyncratic returns $\alpha^{(n)} = \mathbb{E}[u^{(n)}_t] \in \mathbb{R}$ for $n \in [N]$. For a particular investment $\mathcal{I} \in \mathbb{I}$, the corresponding betas are defined as the covariance of the excess returns with the factors divided by variances of the factors: $\beta^{(k)} = \mathbb{V}\text{ar}[f_t^{(k)}]^{-1} \text{Cov}[R_t^{\text{p}} - R^{\text{rf}}_t, f_t^{(k)}] \in \mathbb{R}$ for $k \in [K]$.

\paragraph{Risk premiums} The risk premiums of the factors are given its expectation $\mathbb{E}[\mathbf{f}_t] \in \mathbb{R}^K$. Intuitively, these risk premiums represent the excess returns that we expect to get from taking on the systematic risk associated with the factors. In contrast, the alpha parameter represents the additional expected excess return that are not explained by the factors. As a result, investors are often interested in designing strategies with positive alpha. That is, strategies whose expected performance exceed what the conventional excess returns are (as dictated by the risk premiums and the betas) for the associated risk that is taken on.

\paragraph{Structural assumptions} If we assume the following structural assumptions:
\begin{enumerate}
	\item The factor loadings are deterministic.
	\item The idiosyncratic risk of the assets are uncorrelated with the factor returns.
	\item The idiosyncratic risk are uncorrelated with each other.
\end{enumerate}
Then the variance of the excess returns reduces down to
\begin{align}
	\mathbb{V}\text{ar}[R_t^{\text{p}}]
	&= \mathbf{w}^T \left( \mathbf{B}_t\mathbb{V}\text{ar}[\mathbf{f}_t] \mathbf{B}_t^T + \mathbb{V}\text{ar}[\mathbf{u}_t]\right) \mathbf{w}
	= \mathbf{w}^T \boldsymbol{\Sigma}_t \mathbf{w}.
\end{align}
Equipped with this expression, one only needs to estimate $\mathcal{O}(K^2 + N)$ number of parameters in order to obtain the covariance matrix of interest $\boldsymbol{\Sigma}_t$. Clearly, this reduction in dimensionality is very desirable because the number of factors $K$ is often several times smaller than the number of assets $N$. As a result, it is very common to see these structural assumptions being used together in practice. 

\paragraph{Data processing} As with any data-driven model, some care has to be taken when setting up the exposure matrix. In particular, it is often advised to perform some level of standardisation, normalisation and outlier handling in order to construct the matrix---see the handbook by \cite{axioma2007}.

\paragraph{Choosing the factors} The $K$ factors in the multi-factor model \eqref{eqn:multi_factor_model} are generally chosen either manually or systematically based on a mixture of domain expertise and historical data analysis. There is no consensus on what the best factors to use are. In fact, there is a whole zoo of factors which have been suggested by different authors \citep{feng2020jf}. Notably, the most famous factor models are the Capital Asset Pricing Model \citep{sharpe1964jf}, the Arbitrage Pricing Theory model \citep{ross1976joet}, the Fama-French three-factor model \citep{fama1993jofe}, the Carhart four-factor model \citep{carhart1997jf} and the Fama-French five-factor model \citep{fama2015jofe}.

\paragraph{Estimating the unknowns} The main parameters of the linear model \eqref{eqn:multi_factor_model} are the exposure matrix $\mathbf{B}_t$ and the factor returns $\mathbf{f}_t$. In practice, both of these variables might not be known and therefore one might be interested in constructing an estimate of these unknowns based on what data is available $\mathcal{D}_t$. Depending on what we do know, the strategy that we take to estimate the corresponding unknowns would differ---see the work by \cite{giglio2022arfe} for a review. 
\begin{itemize}
	\item If $\mathbf{B}_t$ is known, then we can estimate $\mathbf{f}_t$ using cross-sectional regression. That is, we regress using data obtained at a specific slice in time. Commonly, one uses a standard linear regression strategy or some (robust) variant thereof to accomplish this.
	\item Similarly, if $\mathbf{f}_t$ is known, then we can estimate $\mathbf{B}_t$ using time-series regression. That is, we regress using data obtained over many slices of time.
	\item If both $\mathbf{B}_t$ and $\mathbf{f}_t$ are unknown, then we can try to estimate these two unknowns jointly using a statistical strategy such as Principle Component Analysis (PCA). Notably, if a PCA strategy is adopted, then the resulting estimate for the latent exposures and factors are not uniquely defined. In particular, appropriate rotations of these  latent quantities lead to equally viable results.
\end{itemize}

\paragraph{Estimating the risk premiums} When the factor returns corresponds to the excess returns of a portfolio that is tradeable, then the corresponding risk premiums can be estimated using a simple sample average of the observed excess returns. When the factor returns corresponds to a non-tradeable quantity, that is, factors that are not portfolios, then some additional work has to be done. In particular, the most prevalent strategy is to construct a tradeable portfolio, which in some sense mimics the behaviour of this non-tradeable factor. At a mathematical level, this problem reduces down to finding a weight vector which best matches this factor---see \citet[Section 3.3]{giglio2022arfe} for more details. As a consequence of these ideas, one can, without loss of generality, write the vector of factor returns as a projection of the asset returns: 
\begin{equation}
	\mathbf{f}_t = \mathbf{H}_t^T \mathbf{R}_t \in \mathbb{R}^K,
\end{equation}
where $\mathbf{H}_t = (\mathbf{h}_t^{(1)}, \dots, \mathbf{h}_t^{(K)}) \in \mathbb{R}^{K \times N}$ with $\mathbf{h}_t^{(k)} \in \mathbb{R}^N$ representing the weight vector associated with factor $k \in [K]$. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Single factor model}
When we have only a single factor, $K=1$, then \eqref{eqn:multi_factor_model} reduces down to the single factor model
\begin{equation}
	R_t^{\text{p}} - R^{\text{rf}}_t = \sum_{n=1}^N w^{(n)} B_t^{(n)} f_t + \sum_{n=1}^N w^{(n)} u^{(n)}_t
	\label{eqn:single_factor_model}
\end{equation}
at time $t>0$. A special case of this single factor model is the Capital Asset Pricing Model (CAPM) \citep{sharpe1964jf}. In this model, we assume that the excess returns obeys \eqref{eqn:single_factor_model} and satisfies the following conditions:
\begin{enumerate}
	\item The factor return is equal to the excess market returns: $f_t = R^{\text{m}}_t - R^{\text{rf}}_t$.
	\item The expectation of the residuals are zero: $\mathbb{E}[u^{(n)}_t] = 0$ for $n \in [N]$.
	\item The residuals are uncorrelated with each other: $\mathbb{E}[u^{(n)}_t u^{(n')}_t] = 0$ for $n \neq n' \in [N]$.
\end{enumerate}
Following \citet[Chapter 1]{grinold1999}, one can define the alpha and beta of this investment as the intercept and gradient of the least squares fit obtained by regressing the excess return of the investment with the excess market return:
\begin{equation}
	R_t^{\text{p}} - R^{\text{rf}}_t
	= \alpha_t + \beta_t (R^{\text{m}}_t - R^{\text{rf}}_t) + \xi_t,
\end{equation}
where $\xi_t$ is the residual which is assumed to have zero mean and 
\begin{equation}
	\beta_t = \frac{\text{Cov}[R_t^{\text{p}} - R^{\text{rf}}_t, R^{\text{m}}_t - R^{\text{rf}}_t]}{ \mathbb{V}\text{ar}[R^{\text{m}}_t - R^{\text{rf}}_t]}.
\end{equation} 
Notice that the second CAPM assumption is in essence equal to the statement that $\alpha_t = 0$. That is, investors are only rewarded for bearing the systematic risk associated with the market. The only difference between investors is their risk tolerance. The amount of risk is dictated by the $\beta_t$ parameter. When $\beta_t=1$, we assume the same risk as the market; when beta is greater (or smaller) than one, we assume more (or less) risk than the market, respectively. Naturally, the more risk we take on, the greater the expected return we expect to get. 

A common criticism about CAPM is that it is too simple in the sense that it is unlikely that the excess market return is the only factor which determines the returns systematic return and risk.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Arbitrage pricing theory}
Arbitrage Pricing Theory (APT) is a generalisation to CAPM. Instead of just using a single factor, \cite{ross1976joet} proposes using the multi-factor model \eqref{eqn:multi_factor_model}. Similarly with CAPM, the APT model assumes some additional properties on the expectations of the idiosyncratic risk and factors: 
\begin{enumerate}
	\item The expected values of the idiosyncratic risk are zero: $\mathbb{E}[u_t^{(n)}] = 0$ for all $n \in [N]$.
	\item  The residuals are uncorrelated with each other: $\mathbb{E}[u^{(n)}_t u^{(n')}_t] = 0$ for $n \neq n' \in [N]$.
	\item  The residuals are uncorrelated with the factor returns: $\mathbb{E}[u^{(n)}_t f^{(k)}_t] = 0$ for $n \in [N]$ and $k \in [K]$.
\end{enumerate}
In contrast with CAPM, these assumptions are based on a well-known arbitrage argument. More specifically, suppose that the multi-factor model \eqref{eqn:multi_factor_model} holds and the APT assumptions do not. Then, whenever one manages to identify a mispriced investment (according to the factor model), one can potentially design a long-short type portfolio in order to generate returns without any expense---an example of such a strategy is outlined by \citet[Chapter 7]{grinold1999}. In other words, these APT assumptions are sufficient in order to prevent these arbitrage opportunities.

A common criticism about the APT model is that it does not tell use what factors to use. As a result, many practitioners often favour more explicit models which tells us explicitly what factors to use, such as the Fama-French models \citep{fama1993jofe,fama2015jofe}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plainnat}
\bibliography{factor}
\end{document}