\documentclass[12pt]{article}

% change to a4 layout
\usepackage{geometry}
\geometry{
	a4paper,
	total={170mm,257mm},
	left=20mm,
	top=15mm,
}

% maths packages
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{bbm}

% references
\usepackage{natbib}

% table packages
\usepackage{booktabs} 

% colour
\usepackage{xcolor}

% enumerate
\usepackage[shortlabels]{enumitem}

% images
\usepackage{graphicx}
\graphicspath{ {figures/} }

% theorems
% \newtheorem{definition}{Definition}[section]
% \newtheorem{lemma}{Lemma}[section]
% \newtheorem{proposition}{Proposition}[section]
% \newtheorem{theorem}{Theorem}[section]
\newtheorem{remark}{Remark}[section]
% \newtheorem{example}{Example}[section]
% \newtheorem{corollary}{Corollary}[section]
% \newtheorem{assumption}{Assumption}[section]

% full stop after paragraph
\makeatletter
\renewcommand\paragraph{%
	\@startsection{paragraph}
	{4}
	{\z@}
	{3.25ex \@plus1ex \@minus.2ex}
	{-1em}
	{\normalfont\normalsize\bfseries\maybe@addperiod}%
}
\newcommand{\maybe@addperiod}[1]{%
	#1\@addpunct{.}%
}
\makeatother

% hyperlinks
\usepackage[pagebackref]{hyperref}       
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=blue,
	citecolor=blue,      
	urlcolor=blue,
}
\renewcommand*{\backref}[1]{}
\renewcommand*{\backrefalt}[4]{%
	\ifcase #1 Not cited.%
	\or        Cited on page~#2.%
	\else      Cited on pages~#2.%
	\fi}

% reference   
\usepackage{cleveref}
\crefname{section}{Section}{Sections}
% \crefname{figure}{Figure}{Figures}
% \crefname{definition}{Definition}{Definitions}
% \crefname{lemma}{Lemma}{Lemmas}
% \crefname{proposition}{Proposition}{Propositions}
% \crefname{theorem}{Theorem}{Theorems}
\crefname{remark}{Remark}{Remarks}
% \crefname{corollary}{Corollary}{Corollaries}
% \crefname{appendix}{Appendix}{Appendices}
% \crefname{assumption}{Assumption}{Assumptions}
% \crefname{example}{Example}{Examples}
% \crefname{table}{Table}{Tables}

% references
\renewcommand\bibname{References}
\usepackage[nottoc,numbib]{tocbibind}

% paragraphs
\usepackage[parfill]{parskip}

% caption
\usepackage[font=footnotesize,labelfont=bf, textfont=it]{caption}

% correct bookmarks
\usepackage{crossreftools}
\pdfstringdefDisableCommands{%
	\let\Cref\crtCref
	\let\cref\crtcref
}

% definitions of some handy macros
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

\title{Active portfolio management}
\author{
	b-tu
}

\begin{document}
\maketitle
The goal of this article is to present a focussed and subjective summary on the ideas covered in the book by \cite{grinold1999} and the surrounding literature.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Notation}
For additional generality, we adopt our own notation in this work, which differs slightly from the notation adopted by \cite{grinold1999}. For bookkeeping purposes, we now highlight some of the key notation that will be used throughout this work.

\paragraph{Space of financial investments.} We let $\mathbb{I}$ denote the space (or universe) of investments. An individual investment will be denoted by $\mathcal{I} \in \mathbb{I}$. Example of investments include both single assets and a weighted collection of assets, otherwise known as a portfolio. For the entirety of this work, we will assume that this space of investments has an intrinsic dimensionality of $N > 0$. That is, the space of investments $\mathbb{I}$ is implicitly governed by a set of $N$ unique assets $\mathbb{A} = \{\mathcal{A}_1, \dots, \mathcal{A}_N\} \subset \mathbb{I}$. Notably, under this set-up, we can identify each possible investment in $\mathbb{I}$ with an $N$-dimensional weight vector, 
\begin{equation}
	\mathcal{I} \in \mathbb{I} \longleftrightarrow \mathbf{h} = (h^{(1)}, \dots, h^{(N)}) \in \mathbb{H},
\end{equation}
where $\mathbb{H}$ denotes the feasible set of weights. For example, a common constraint to enforce in practice is that the weights should sum up to one:
\begin{equation}
	\mathbb{H} = \bigg\{\mathbf{h} \in \mathbb{R}^N: \sum_{n=1}^N h^{(n)} = 1 \bigg\}.
\end{equation}
Conceptually, each component $h^{(n)} \in \mathbb{R}$ controls the weight associated with the asset $\mathcal{A}_n \in \mathbb{A}$ for $n \in [N] := \{1,\dots,N\}$. These weight components can either be positive (for a long position) or negative (for a short position). 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Background concepts}
The goal of this section is to highlight some of the core conventions and ideas that are often present in the finance literature.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Returns}
The return of an investment is often reported in the percentage range. More precisely, one does not report the raw numerical return (i.e.\ the change in profit), but instead one reports the rate of return (i.e.\ the relative change in profit). Concretely, suppose we have an investment $\mathcal{I} \in \mathbb{I}$ whose value is given by $v_{t_0}(\mathcal{I}) \in \mathbb{R}$ at time $t_0$ and $v_T(\mathcal{I}) \in \mathbb{R}$ at some future time $t$, then the return of this investment at this latest time is given by
\begin{equation}
    r_t(\mathcal{I}) = \frac{v_t(\mathcal{I}) - v_{t_0}(\mathcal{I})}{v_{t_0}(\mathcal{I})} \in \mathbb{R}.
    \label{eqn:return}
\end{equation}
Notice that this number tends to infinity when the initial value approaches zero. That is, in the limit we are getting infinite return from a prior investment of nothing.

\begin{remark}
	[Other value streams] In practice, one must also account for other profits gained by holding onto the investment in equation \eqref{eqn:return}. For example, one might also include gains from dividends. Out of convenience, we ignore subtle technicalities such as this.
\end{remark}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Everything is relative}
Performance assessment is traditionally defined on a relative basis. That is, one typically computes the performance of an investment in comparison to another one. Specifically, we are often interested in the return of an investment relative to some benchmark,
\begin{equation}
    R_t(\mathcal{I}, \mathcal{B}) := r_t(\mathcal{I}) - r_t(\mathcal{B}),
    \label{eqn:relative_return}
\end{equation}
where $r_t(\mathcal{I})$ and $r_t(\mathcal{B})$ denotes the return from an investment $\mathcal{I} \in \mathbb{I}$ and benchmark $\mathcal{B} \in \mathbb{I}$, at time $t > 0$, respectively. Practitioners often set this benchmark rate to either the risk-free rate or the market rate. Notably, when the risk-free rate is used, this relative return is referred to as the excess return. Otherwise, this relative return is commonly referred to as the active return.

\paragraph{Risk-free rate} The risk-free rate, $r_t(\mathcal{B}^{\text{free}})$, refers to the (hypothetical) minimum rate of return that one might desire from an investment. Typically, this rate is set to the return of a financial product whose risk is minimal\footnote{Ideally, one would like to consider a zero risk investment---although realistically there is always a risk associated with any investment.}. In practice, it is common to see this rate being set to the return of some Treasury bill (T-bill) or a long-term government bond yield.

\paragraph{Market rate} The market rate, $r_t(\mathcal{B}^{\text{market}})$, usually refers to the return achieved by a financial product that tries to match the market as a whole (or at least some subset of it). This market portfolio is usually constructed by taking all of the assets in the desired market and then weighting them accordingly to their market capitalisation.

\begin{remark}
	[Empty investment] Note that we recover the original notion of return \eqref{eqn:return} if we set our benchmark to the empty investment.
\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The meaning of risk}
Following \cite{grinold1999}, the risk associated with an investment is defined as the standard deviation of its return. More precisely, the risk associated with an investment $\mathcal{I} \in \mathbb{I}$, at a time $t > 0$, is
\begin{equation}
	\text{Risk}[\mathcal{I}] := \text{Std}[r_t(\mathcal{I})] = \sqrt{\mathbb{V}\text{ar}[r_t(\mathcal{I})]},
\end{equation}
and similarly, the risk of the active return \eqref{eqn:relative_return} is 
\begin{equation}
	\text{Risk}[(\mathcal{I}, \mathcal{B})] := \text{Std}[R_t(\mathcal{I}, \mathcal{B})] = \sqrt{\mathbb{V}\text{ar}[R_t(\mathcal{I}, \mathcal{B})]}.
\end{equation}
This latter risk is sometimes referred to as the active risk or the tracking error.

\paragraph{Other measures of risk} As discussed by \citet[Chapter 3]{grinold1999}, there are many possible alternatives to the standard deviation as a notion of risk. Although empirically, they suggest that there is little to gain from exploring these alternatives---at least from a performance-to-cost standpoint.

\paragraph{Idiosyncratic and systematic risk} The risk associated entirely from an individual asset $\mathcal{A} \in \mathbb{I}$ is referred to as the idiosyncratic risk of $\mathcal{A}$. These risk can typically be mitigated (or even eliminated) by constructing a more diversified portfolio. The other sources of risk are collectively referred to as the systematic risk. Conceptually, these are the risk involved with holding any investment. Moreover, by construction, systematic risk cannot be diversified away (i.e.\ they represent the non-diversifiable risk).
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The nature of time}
The distinction between an ex-ante (before the event) approach and an ex-post (after the event) approach is often very subtle in the finance literature. For example, one might take an ex-ante approach when one is interested in forecasting and making predictions of the future. In contrast, one might take an ex-post approach in the performance assessment setting, where one is interested in assessing the quality\footnote{Here the term quality is defined in the philosophical sense. In general, it is very hard to actually quantify what distinguishes a skillful investor and a lucky one.} of a strategy or a portfolio manager.

\paragraph{Risk analysis} A core problem in asset management is concerned with the quantification of risk. It is important to note that one is interested in estimating risk in both the ex-ante and ex-post setting. In the ex-ante setting, we are interested estimating risk in order to incorporate it into our active decision-making. Whilst, in the ex-post setting, we are interested in assessing risk in order to identify its main drivers and also to properly assess the realised performance of an investment or portfolio manager.

\paragraph{Information set} We denote the historical information set, at time $t > 0$, by $\mathcal{D}_t \in \mathbb{D}$, where $\mathbb{D}$ denotes the set of all possible historical information sets. Confusingly, some authors abuse this notation because they allow it to be defined ambiguously in order to accommodate for both the ex-ante and ex-post setting. More specifically, in the ex-ante (or ex-post) setting, these authors let $\mathcal{D}_t$ denote the information set containing all of the information available at the beginning (or end) of time $t$, respectively. This convention is convenient from a writing perspective as it covers both of these temporal settings simultaneously. On the other hand, it is definitely confusing from a reader perspective who could easily be misled. Despite this weakness, we will also follow this convention as it allows for easier comparisons between this document and other related works.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Garbage in, garbage out}
A central tenet that is echoed throughout the book by \cite{grinold1999} is the idea that the ability to identify and exploit ``superior information'' is what separates a good active manager from a bad one. In other words, to generate excess returns, one needs to be diligent in both their ability to collect useful information and also their ability to use it effectively. Most of the work presented by \cite{grinold1999} focusses on addressing the latter problem. We will cover a selection of these ideas in the following sections. The former problem, however, is a practical challenge that is much more an art than a science. Regardless of how one approaches this information retrieval problem, one inevitably will fall upon the well-know adage: ``garbage in, garbage out''. That is, our inability to identify information of a `reasonable' quality will, more often than not, lead to low quality output (i.e.\ garbage). Therefore, it remains an important and unquestionable part of asset management, that one must aspire to collect high quality data in order to facilitate better decision making.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The efficient market hypothesis}
The Efficient-Market Hypothesis (EMH) states that the price of an asset or investment reflects all of the available information. That is, there should not be consistent opportunities for an investor to outperform the market. 

\paragraph{Other variants} There are a number of different variants to the EMH. At a conceptual level, these variants mainly differ on what the notion of ``available information" means. Namely, whether this is just any data available about past prices (weak), any publicly available information (semi-strong) or any possible information that exist in the world (strong). 

\paragraph{Validity} The debate on whether the EMH, or at least some variant of it, holds in practice is a contentious one---\textcolor{red}{TODO:ref something}. Regardless of its validity, there still exist many people out there who continue to try and beat the market: therefore the game goes on!

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Mean-variance trade-off}
\label{sec:mean_variance}
The goal of Modern Portfolio Theory (MPT) \textcolor{red}{TODO: cite Markowitz 1952} is to find portfolios which achieves the greatest expected return for a given user-specified risk level. More formally, suppose we have a risk level of $c \geq 0$, then the goal of interest is to solve the following mean-variance optimisation problem:
\begin{align}
	\max_{\mathbf{h} \in \mathbb{H}} \mathbf{h}^T \boldsymbol{\mu}_t
	\quad
	\text{subject to}
	\quad 
	\mathbf{h}^T\boldsymbol{\Sigma}_t \mathbf{h} \leq c^2,
	\label{eqn:mean_variance_problem}
\end{align}
for any time $t > 0$, where the $\boldsymbol{\mu}_t \in \mathbb{R}^N$ and $\boldsymbol{\Sigma}_t \in \mathbb{R}^{N \times N}$ denotes the mean and covariance matrix of the excess returns of the base assets,
\begin{align}
	\mathbf{R}_t &:= (R_t(\mathcal{A}_1, \mathcal{B}^{\text{free}}), \dots, R_t(\mathcal{A}_N, \mathcal{B}^{\text{free}}))^T \in \mathbb{R}^N,
	\\
	\boldsymbol{\mu}_t &:= \mathbb{E}[\mathbf{R}_t] \in \mathbb{R}^N,
	\\
	\boldsymbol{\Sigma}_t &:= \mathbb{V}\text{ar}[\mathbf{R}_t] \in \mathbb{R}^{N \times N}.
\end{align}
One of the key challenges involved with deploying an MPT solution comes from the fact that the mean vector and covariance matrix of interest is unknown in practice and therefore has to be estimated (or predicted) from the available data $\mathcal{D}_t \in \mathbb{D}$. The mean vector has $N$ elements that has to be estimated, whilst the covariance matrix has $\mathcal{O}(N^2)$ number of elements to be estimated. In practice, one does not usually have enough data points at each time $t$ in order to efficiently estimate the covariance matrix with high precision. As a result, practitioners typically try to reduce the dimensionality of this estimation problem by making some reasonable modelling assumptions on the excess returns of the assets. For instance a popular modelling framework are factor models (\cref{sec:factor_models}), which effectively reduces the dimensionality of the covariance matrix to $\mathcal{O}(K^2 + N)$, where $K$ is the number of factors specified by the user---see \cref{sec:factor_models} for more details.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Modelling the returns}
One of the main problems in active portfolio management is concerned with the modelling of excess returns \eqref{eqn:relative_return}. In particular, one often tries to model the excess returns of an investment $\mathcal{I} \in \mathbb{I}$, at time $t > 0$, as a function of the information set:
\begin{equation}
    R_t(\mathcal{I}, \mathcal{B}^{\text{free}}) = g_t(\mathcal{D}_t) + \epsilon_t,
    \label{eqn:return_model}
\end{equation}
where $\mathcal{D}_t \in \mathbb{D}$ denotes the $t$-th information set, $g_t: \mathbb{D} \rightarrow \mathbb{R}$ denotes a (potentially random) modelling function and $\epsilon_t \in \mathbb{R}$ denotes the random residual. In the following paragraphs, we list some notable ideas that underpin this general model for excess returns \eqref{eqn:return_model}.

\paragraph{Dependence on the investor} Notably, the form of the information set $\mathcal{D}_t$ and modelling function $g_t$ is something that is specified by the user; the residual $\epsilon_t$ denotes everything else that is left over. On practical level, this means that different investors can obtain different results even if they adopt the same modelling function. 

\paragraph{Information uncertainty} In the most general case, the information set can be treated as a random variable. The randomness of this quantity stems from the intrinsic uncertainty that naturally arises from the collection, retrieval and processing of real-world data. Conventionally though, it is common to see this information set (or at least some part of it) being treated as a deterministic realisation of an estimation or computation procedure. This is usually done out of numerical convenience. \textcolor{orange}{Question to consider: Is there anything to gain from a more fully probabilistic treatment?}

\paragraph{Residual uncertainty} The residual $\epsilon_t = R_t(\mathcal{I}, \mathcal{B}^{\text{free}}) - g_t(\mathcal{D}_t)$ models the remaining discrepancy that is not accounted for by the ``explained'' part of the excess returns $g_t(\mathcal{D}_t)$. Note here that the residual $\epsilon_t$ is a random variable because the excess returns is modelled as a random variable.

\paragraph{Space of models} The modelling function $g_t$ is assumed to live in some reasonably flexible space. For example, much of the earlier work in the space considered the space of linear functions. More recently, there has been a growing interest in using machine learning methods in order to learn more expressive non-linear models.

\paragraph{Imposing structure on the risk} As highlighted in \cref{sec:mean_variance}, a useful consequence of modelling the excess returns is that the resulting covariance matrix might become easier to estimate. For this purpose, it is common to try to embed some structure into the model which helps facilitate this dimensionality reduction. In particular, a common strategy is to enforce that the``explained'' part of the model $g_t(\mathcal{D}_t)$ is used to account for the systematic returns (and risk), whilst the remaining part $\epsilon_t$ accounts for the idiosyncratic return (and risk). Such a structure is imposed in factor models. \textcolor{orange}{Question to consider: Is this strategy always the best way to proceed?}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Factor models}
\label{sec:factor_models}
Early work on modelling returns centred on the setting where the space of models was the space of linear models. In particular, the factor models tries to relate the excess returns of an asset with the returns of different factors. These factors are user-specified and therefore this linear modelling framework offers a lot of flexibility. Despite this, it is common for practitioners to use well-known factors that have been proposed before in the literature. We will now present a targetted overview on this topic. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Multi-factor model} Given an investment $\mathcal{I} \in \mathbb{I}_N$, represented by a weight vector $\mathbf{h} \in \mathbb{H}_N$, the multi-factor model assumes that the excess returns obeys the following linear model
\begin{align}
	R_t(\mathcal{I}, \mathcal{B}^{\text{free}}) 
	&= \mathbf{h}^T (\mathbf{B}_t \mathbf{f}_t + \mathbf{u}_t)
	\\
	&= \sum_{k=1}^K \left(\sum_{n=1}^N h^{(n)} B_t^{(n, k)} \right) f_t^{(k)} + \sum_{n=1}^N h^{(n)} u^{(n)}_t,
	\label{eqn:multi_factor_model}
\end{align}
at time $t>0$. The variables in the model are outlined as follows:
\begin{itemize}
	\item $\mathbf{f}_t = (f_t^{(1)}, \dots, f_t^{(K)})^T \in \mathbb{R}^K$ is the factor returns vector. This vector is generally treated as a random variable.
	\item $\mathbf{B}_t \in \mathbb{R}^{N \times K}$ is the exposure matrix, whose elements $B_t^{(n, k)} \in\ \mathbb{R}$ are the factor loadings which represent the exposure (or sensitivity) of asset $n \in [N]$ to factor $k \in [K]$. This is commonly treated as a deterministic variable.
	\item $\mathbf{u}_t = (u_t^{(1)}, \dots, u_t^{(N)})^T \in \mathbb{R}^N$ are the asset residuals or the idiosyncratic returns. Namely, these are the excess returns of an asset that cannot be explained by the (systematic) factors.
\end{itemize}
The expectation and variance of \eqref{eqn:multi_factor_model} is then given by:
\begin{align}
	\mathbb{E}[R_t(\mathcal{I}, \mathcal{B}^{\text{free}})] &= \mathbf{h}^T (\mathbb{E}[\mathbf{B}_t \mathbf{f}_t] + \mathbb{E}[\mathbf{u}_t]),
	\\
	\mathbb{V}\text{ar}[R_t(\mathcal{I}, \mathcal{B}^{\text{free}})] 
	&= \mathbf{h}^T \mathbb{V}\text{ar}[\mathbf{B}_t \mathbf{f}_t + \mathbf{u}_t] \mathbf{h}
	\\
	&= \mathbf{h}^T \left(\mathbb{V}\text{ar}[\mathbf{B}_t \mathbf{f}_t] + 2\mathbb{C}\text{ov}[\mathbf{B}_t \mathbf{f}_t, \mathbf{u}_t] + \mathbb{V}\text{ar}[\mathbf{u}_t]\right) \mathbf{h}.
\end{align}

\paragraph{Alphas and betas} We can rewrite the multi-factor model \eqref{eqn:multi_factor_model} in terms of the conventional alpha and beta parameters that arise in standard linear regression. More specifically, the alpha parameter $\alpha_t \in \mathbb{R}$ corresponds to the intercept of the linear model, the beta parameters $\boldsymbol{\beta}_t \in \mathbb{R}^K$ corresponds to the coefficients of the factor returns and $\xi_t \in \mathbb{R}$ is remaining zero-mean random residual:
\begin{equation}
	R_t(\mathcal{I}, \mathcal{B}^{\text{free}}) 
	= \alpha_t + \sum_{k=1}^K \beta_t^{(k)} f_t^{(k)} + \xi_t,
\end{equation}
where $\alpha_t + \xi_t = \sum_{n=1}^N h^{(n)} u_t^{(n)}$ and $\beta_t^{(k)} = \sum_{n=1}^N h^{(n)} B_t^{(n, k)}$ for $k \in [K]$ and $t > 0$. Notably, it is not hard to see that the alpha and beta parameters of an investment $\mathcal{I} \in \mathbb{I}$ is just a weighted combination of the corresponding alpha and betas associated with the individual assets $\mathcal{A}_n \in \mathbb{A}$, respectively. More precisely, the individual betas for the assets is given by the corresponding components of the exposure matrix $\mathbf{B}_t$ and the individual alphas is given by the expectation of the idiosyncratic returns $\mathbf{u}_t$.

\paragraph{Structural assumptions} If we assume the following structural assumptions:
\begin{enumerate}
	\item The factor loadings are deterministic.
	\item The idiosyncratic risk of the assets are uncorrelated with the factor returns.
	\item The idiosyncratic risk are uncorrelated with each other.
\end{enumerate}
Then the variance of the excess returns reduces down to
\begin{align}
	\mathbb{V}\text{ar}[R_t(\mathcal{I}, \mathcal{B}^{\text{free}})]
	&= \mathbf{h}^T \left( \mathbf{B}_t\mathbb{V}\text{ar}[\mathbf{f}_t] \mathbf{B}_t^T + \mathbb{V}\text{ar}[\mathbf{u}_t]\right) \mathbf{h}
	= \mathbf{h}^T \boldsymbol{\Sigma}_t \mathbf{h}.
\end{align}
Equipped with this expression, one only needs to estimate $\mathcal{O}(K^2 + N)$ number of parameters in order to obtain the covariance matrix of interest $\boldsymbol{\Sigma}_t$. Clearly, this reduction in dimensionality is very desirable because the number of factors $K$ is often several times smaller than the number of assets $N$. As a result, it is very common to see these structural assumptions being used together in practice. 

\paragraph{Data processing} As with any data-driven model, some care has to be taken when setting up the exposure matrix. In particular, it is often advised to perform some level of standardisation, normalisation and outlier handling in order to construct the matrix. \textcolor{red}{TODO:maybe ref something}.

\paragraph{Choosing the factors} The $K$ factors in the multi-factor model \eqref{eqn:multi_factor_model} are generally chosen either manually or systematically based on a mixture of domain expertise and historical data analysis. There is no consensus on what the best factors to use are. In fact, there is a whole zoo of factors which have been suggested by different authors \textcolor{red}{TODO:ref}. Notably, the most famous factor models are the ones proposed by \cite{fama1993jofe} etc. \textcolor{red}{TODO:add more references}.

\paragraph{Estimating the unknowns} The main parameters of the linear model \eqref{eqn:multi_factor_model} are the exposure matrix $\mathbf{B}_t$ and the factor returns $\mathbf{f}_t$. In practice, both of these variables might not be known and therefore one might be interested in constructing an estimate of these unknowns based on what data is available $\mathcal{D}_t$. Depending on what we do know, the strategy that we take to estimate the corresponding unknowns would differ. For example, if we only know $\mathbf{B}_t$, then we can estimate $\mathbf{f}_t$ using cross-sectional regression. That is, we regress using data obtained at a specific slice in time. For instance, we can use a standard linear regression strategy or some (robust) variant thereof. Similarly, if we only know $\mathbf{f}_t$, then we can estimate $\mathbf{B}_t$ using time-series regression. That is, we regress using data obtained over many slices of time. In the case where both $\mathbf{B}_t$ and $\mathbf{f}_t$ are unknown, then we can try to estimate these two unknowns jointly using a statistical strategy such as principle component analysis.

\begin{remark}
	[Excess asset returns] Traditionally, the multi-factor model \eqref{eqn:multi_factor_model} are used to model the excess returns of the base assets $\mathbb{A}$. In particular, the unknown parameters of this model are usually estimated based on the observed excess asset returns and not the returns of different portfolios. \textcolor{orange}{Question to consider: Although this makes sense from a practical level, are there occasions where modelling portfolio excess returns is better?}
\end{remark}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Single factor model}
When we have only a single factor, $K=1$, then \eqref{eqn:multi_factor_model} reduces down to the single factor model
\begin{equation}
	R_t(\mathcal{I}, \mathcal{B}^{\text{free}}) = \sum_{n=1}^N h^{(n)} B_t^{(n)} f_t + \sum_{n=1}^N h^{(n)} u^{(n)}_t
	\label{eqn:single_factor_model}
\end{equation}
at time $t>0$. A special case of this single factor model is the Capital Asset Pricing Model (CAPM) \textcolor{red}{TODO:ref Sharpe 1964}. In this model, we assume that the excess returns obeys \eqref{eqn:single_factor_model} and satisfies the following conditions:
\begin{enumerate}
	\item The factor return is equal to the excess market returns: $f_t = R_t(\mathcal{B}^{\text{market}}, \mathcal{B}^{\text{free}})$.
	\item The expectation of the residuals are zero: $\mathbb{E}[u^{(n)}_t] = 0$ for $n \in [N]$.
	\item The residuals are uncorrelated with each other: $\mathbb{E}[u^{(n)}_t u^{(n')}_t] = 0$ for $n \neq n' \in [N]$.
\end{enumerate}
Following \citet[Chapter 1]{grinold1999}, one can define the alpha and beta of this investment as the intercept and gradient of the least squares fit obtained by regressing the excess return of the investment with the excess market return:
\begin{equation}
	R_t(\mathcal{I}, \mathcal{B}^{\text{free}})
	= \alpha_t + \beta_t R_t(\mathcal{B}^{\text{market}}, \mathcal{B}^{\text{free}}) + \xi_t,
\end{equation}
where $\xi_t$ is the residual which is assumed to have zero mean and 
\begin{equation}
	\beta_t = \frac{\mathbb{C}\text{ov}[R_t(\mathcal{I}, \mathcal{B}^{\text{free}}), R_t(\mathcal{B}^{\text{market}}, \mathcal{B}^{\text{free}})]}{ \mathbb{V}\text{ar}[R_t(\mathcal{B}^{\text{market}}, \mathcal{B}^{\text{free}})]}.
\end{equation} 
Notice that the second CAPM assumption is in essence equal to the statement that $\alpha_t = 0$. That is, investors are only rewarded for bearing the systematic risk associated with the market. The only difference between investors is their risk tolerance. The amount of risk is dictated by the $\beta_t$ parameter. When $\beta_t=1$, we assume the same risk as the market; when beta is greater (or smaller) than one, we assume more (or less) risk than the market, respectively. Naturally, the more risk we take on, the greater the expected return we expect to get. 

A common criticism about CAPM is that it is too simple in the sense that it is unlikely that the excess market return is the only factor which determines the returns systematic return and risk.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsubsection{Arbitrage pricing theory}
The Arbitrage Pricing Theory (APT) is a generalisation to CAPM. Instead of just using a single factor, \textcolor{red}{TODO: cite Ross 1976} proposes using the multi-factor model \eqref{eqn:multi_factor_model}. Similarly with CAPM, the APT model assumes some additional properties on the expectations of the idiosyncratic risk and factors: 
\begin{enumerate}
	\item The expected values of the idiosyncratic risk are zero: $\mathbb{E}[u_t^{(n)}] = 0$ for all $n \in [N]$.
	\item  The residuals are uncorrelated with each other: $\mathbb{E}[u^{(n)}_t u^{(n')}_t] = 0$ for $n \neq n' \in [N]$.
	\item  The residuals are uncorrelated with the factor returns: $\mathbb{E}[u^{(n)}_t f^{(k)}_t] = 0$ for $n \in [N]$ and $k \in [K]$.
\end{enumerate}
In contrast with CAPM, these assumptions are based on a well-known arbitrage argument. More specifically, suppose that the multi-factor model \eqref{eqn:multi_factor_model} holds and the APT assumptions do not. Then, whenever one manages to identify a mispriced investment (according to the factor model), one can potentially design a long-short type portfolio in order to generate returns without any expense---an example of such a strategy is outlined by \citet[Chapter 7]{grinold1999}. In other words, these APT assumptions are sufficient in order to prevent these arbitrage opportunities.

A common criticism about the APT model is that it does not tell use what factors to use. As a result, many practitioners often favour more explicit models which gives us the recipe of the factors to use are. For example, the\cite{fama1993jofe} models etc. \textcolor{red}{TODO:add ref}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Machine learning}
\textcolor{red}{TODO: draft some preliminary ideas.}
%Given a fixed form for the information set $H_t$, it is tempting to treat \eqref{eqn:return_model} and \eqref{eqn:expected_return_model} as a classic machine learning problem. That is, we select the function $f$ or $g$ from a particularly expressive family of models $\mathbb{M}$ and minimise some reasonable loss function in order to find the ``best'' model. 
%
%\paragraph{Regression on the excess returns} To find the best model for \eqref{eqn:return_model}, we just minimise some discrepancy $\mathcal{D}$ between the distribution of excess returns and distribution of explained excess returns over time. For instance, we can minimise the integrated discrepancy:
%\begin{equation}
%    f^* \in \argmin_{f \in \mathbb{M}} \int_{t \in \mathbf{T}} \mathcal{D}(\mathcal{R}_t, f(H_t)) dt,
%\end{equation}
%for some appropriate time horizon $\mathbf{T}$.
%
%\paragraph{Regression on the expected excess returns} To find the best model for \eqref{eqn:expected_return_model}, we just minimise some scoring function $S$ between the expected excess returns and distribution of explained excess returns over time. For instance, we can minimise the integrated score:
%\begin{equation}
%    g^* \in \argmin_{g \in \mathbb{M}} \int_{t \in \mathbf{T}} S(g(H_t), \bar{\mathcal{R}}_t) dt,
%\end{equation}
%for some appropriate time horizon $\mathbf{T}$.
%\\ \\
%Both of these models rely on quantities or things we might not be able to compute or optimise in practice. They are just equations to keep in mind. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\section{Mean-variance trade-off}
%\section{Cross-sectional vs time series}
%\section{Linear vs non-linear}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\bibliographystyle{plainnat}
\bibliography{factor}
\end{document}